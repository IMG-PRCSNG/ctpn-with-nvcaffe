{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CTPN and NVCaffe",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOyL7EdiEsbQX3CVwp1uvd0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/IMG-PRCSNG/ctpn-with-nvcaffe/blob/master/ctpn_with_nvcaffe.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sw33gqy33SDB",
        "colab_type": "text"
      },
      "source": [
        "# CTPN\n",
        "\n",
        "CTPN is a deep learning based text detection algorithm for detecting text in natural images.\n",
        "\n",
        "CTPN stands for `Connectionist Text Proposal Network`. It implements a combination of CNN and LSTM layers in its architecture to make proposals of where a text line exists (localisation) and confidence scores for the proposals. \n",
        "\n",
        "From the CNN parts, we get rich feature maps that provides information to the LSTM layers in predicting if the given sequence of fixed-width boxes belongs to a text line or not. \n",
        "\n",
        "There is also a vertical anchor mechanism to accont for textlines that span multiple vertical sequences to improve localisation accuracy.\n",
        "\n",
        "Non maximum suppression is applied as post processing to combine / break down overlapping proposals.\n",
        "\n",
        " Links:\n",
        "\n",
        " - [Paper](https://arxiv.org/abs/1609.03605)\n",
        " - [Code](https://github.com/tianzhi0549/CTPN) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3iDPfTOcD1fV",
        "colab_type": "text"
      },
      "source": [
        "# NVCaffe\n",
        "\n",
        "[Caffe](https://github.com/BVLC/caffe) is a Deep Learning Framework written in `C++` by folks at Berkley AI Research / Berkely Vision and Learning Center. The framework lets you chain multiple layers together to form a Deep Neural Network.\n",
        "\n",
        "[NVCaffe](https://github.com/nvidia/caffe) is a fork maintained by NVIDIA. It is fully compatible with BVLC caffe and offers additional features like\n",
        "- Support for `FP16` in inference\n",
        "- Support for latest `CUDA`(10+) and `CUDNN`(7+)\n",
        "- Optimized multi-GPU training with `NCCL`\n",
        "- Optimized memory management\n",
        "- Experimental support for TensorRT layer\n",
        "- and much more"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Jx4bOt9aLNa",
        "colab_type": "text"
      },
      "source": [
        "# Running CTPN with NVCaffe\n",
        "\n",
        "This project attempts to run the Text Detection Algorithm CTPN with the latest version of NVCaffe.\n",
        "\n",
        "To showcase, we are going to run this on `Google Colab VM` with GPU Support.\n",
        "\n",
        "Hit `Connect / Reconnect` on the toolbar (top-right) to connect to one now.\n",
        "\n",
        "\n",
        "*Note: If you are familiar with docker, and would like to try on your own machine, you can directly use the github [package](https://github.com/IMG-PRCSNG/CTPN/packages/300024). It comes with nvcaffe and ctpn pre-installed. Usage Instructions: coming soon*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kpE7kBjAofVw",
        "colab_type": "text"
      },
      "source": [
        "## Requirements\n",
        "\n",
        "To run CTPN with the latest version of NVCaffe\n",
        "\n",
        "- GPU (Google Colab provides free GPU time for experiments)\n",
        "\n",
        "- Port the following custom layers to NVcaffe written\n",
        "  - Reverse\n",
        "  - Transpose\n",
        "  - Lstm\n",
        "\n",
        "- Compile and exeute CTPN module\n",
        "\n",
        "\n",
        "The layer porting is done and is being maintained in this [repo](https://github.com/IMG-PRCSNG/caffe).\n",
        "A pre-compiled version for `Ubuntu 18.04 + CUDA 10.1 + CUDNN 7.6` was extracted from the docker image in that repo and is shipped in this repo for making it simple to test on non docker environments like Colab.\n",
        "\n",
        "\n",
        "*Note: If you are familiar with docker, you can use the pre-compiled NVCaffe (compiled for K, M, P, V, T series GPUs) from [here](https://github.com/IMG-PRCSNG/caffe/packages/299482).* \n",
        "\n",
        "*Check this [`Dockerfile`](https://github.com/IMG-PRCSNG/caffe/blob/caffe-0.17/Dockerfile) for contents and this [`Dockerfile.ctpn`](https://github.com/IMG-PRCSNG/CTPN/blob/master/Dockerfile.ctpn) for example usage*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TyRgEEwXHRst",
        "colab_type": "text"
      },
      "source": [
        "## Warning\n",
        "\n",
        "The following scripts are intended to be run in Colab / other disposable environments. The script makes changes to the root directory `/` and is not easily reversible. Use it at your own discretion in your own environments after reading what is inside the files."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o5ELUM7cew_q",
        "colab_type": "text"
      },
      "source": [
        "## Setup\n",
        "\n",
        "A broad overview steps required to run CTPN with NVCaffe are as follows:\n",
        "\n",
        "1. Clone this [repo](https://github.com/IMG-PRCSNG/ctpn-with-nvcaffe.git) which has helper scripts to setup the colab environment\n",
        "2. Initialise LFS\n",
        "3. Install the system, python and NVCaffe dependencies\n",
        "4. Copy the model to the correct folder\n",
        "5. Run the bundled demo to check if everything is working\n",
        "\n",
        "Before we begin let's switch our working directory to `/content`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YadvwuqTsMVp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%cd /content"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_uwKqDJTbiXP",
        "colab_type": "text"
      },
      "source": [
        "### Cloning the Repo\n",
        "\n",
        "This repo consists of\n",
        "\n",
        "- Setup script to install dependencies using ansible for running caffe and CTPN on a ubuntu18.04 machine\n",
        "- Pre-compiled tarball of NVCaffe compatible with the environment setup by the scripts in this repo.\n",
        "- CTPN model from this [repo](https://github.com/tianzhi0549/CTPN)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6kH6h2UOc5LL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Run this once.\n",
        "!git clone https://github.com/IMG-PRCSNG/ctpn-with-nvcaffe \n",
        "%cd /content/ctpn-with-nvcaffe"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c82SbJLAf0Qe",
        "colab_type": "text"
      },
      "source": [
        "### Ansible\n",
        "\n",
        "From the [wikipage](https://en.wikipedia.org/wiki/Ansible_(software)), \n",
        "\n",
        "*Ansible is an open-source software provisioning, configuration management, and application-deployment tool enabling infrastructure as code.*\n",
        "\n",
        "We will be using `ansible playbooks` to manage our dependencies for this project\n",
        "\n",
        "The main advantage comes from the fact that\n",
        "- Easy to learn and use.\n",
        "- Ansible is written in YAML. More human-readable than bash scripts.\n",
        "- Most ansible modules are idempotent. You can run them over and over and ansible will ensure the desired state is present.\n",
        "- Manage multiple environments with OpenSSH and Python\n",
        "\n",
        "To install ansible\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_CJVKXpFg32l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Installing ansible with\n",
        "!pip install ansible"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2UXvD7sOaovP",
        "colab_type": "text"
      },
      "source": [
        "### Git LFS\n",
        "\n",
        "Git LFS stands for Git Large File Storage. It is useful for, well, storing large files. It checks out a pointer to the file when you clone the repo and do repo operations and will only fetch the actual file when you do a checkout.\n",
        "\n",
        "This is particularly useful in large repos where there are multiple versions of DL models in VCS. Pulling / pushing all the versions will consume significant time, storage and bandwidth.\n",
        "\n",
        "More info: [Git LFS Website](https://git-lfs.github.com/)\n",
        "\n",
        "[`install-lfs.yml`](https://github.com/IMG-PRCSNG/ctpn-with-nvcaffe/blob/master/install-lfs.yml) consists of instructions to install and initialise LFS\n",
        "\n",
        "We can run it as\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kfRVFC29aohR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!ansible-playbook install-lfs.yml --extra-vars=hosts=localhost"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yJeSakhpuA7V",
        "colab_type": "text"
      },
      "source": [
        "We can now checkout the lfs files present in this particular commit with"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mJoL5QNauLT0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!git lfs fetch && git lfs checkout"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5iF5ahYDeZ-x",
        "colab_type": "text"
      },
      "source": [
        "### Dependencies\n",
        "\n",
        "We have a lot of system and python dependencies for running Caffe and a few python dependencies for compiling and running CTPN\n",
        "\n",
        "To set that up, we are going to run the [`install-dependencies.yml`](https://github.com/IMG-PRCSNG/ctpn-with-nvcaffe/blob/master/install-dependencies.yml) playbook which will\n",
        "\n",
        "- Install system dependencies\n",
        "- Clone CTPN repo\n",
        "- Compile CTPN\n",
        "- Copy Model to the path expected.\n",
        "\n",
        "We can run that with"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vsWG9x1cesWK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!ansible-playbook install-dependencies.yml --extra-vars=hosts=localhost"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b03vdwjdlh0e",
        "colab_type": "text"
      },
      "source": [
        "### Optional: All in One Script\n",
        "\n",
        "There is a helper script which will do all the above. You can run it with `bash setup.sh`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ucP1eYNVxYs2",
        "colab_type": "text"
      },
      "source": [
        "## Drive Sync\n",
        "\n",
        "Mounting your google drive folder will let you easily sync files between your Google Drive and the Colab VM Runtime. This comes in handy if you want to persist certain files beyond the lifecycle of a Colab Runtime and save time when re-starting a session.\n",
        "\n",
        "This can be used for non-code files which don't usually reside in your VCS - like input and output images, model checkpoints, logs, config, etc\n",
        "\n",
        "To mount your google drive, run the following cell and follow the instructions - This will sync files from VM to Google Drive. \n",
        "\n",
        "Optionally, You can setup Google Drive sync on your personal computer to sync these files and manipulate them directly from your Personal computer. A very good use case will be your configurations - you can quickly manipulate the configs and restart the process consuming it without having to manually push and pull.\n",
        "\n",
        "\n",
        "Have a look at this [blog post](https://dev.to/kriyeng/8-tips-for-google-colab-notebooks-to-take-advantage-of-their-free-of-charge-12gb-ram-gpu-be4) for more tips on using Colab Notebooks for ML / DL experiments."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jnYxw1dTdvay",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "# Now, anything you add to /content/gdrive/ will be be synced to GDrive,\n",
        "# and will also be synced to your PC if you have setup GDrive <-> PC sync\n",
        "# as well."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7365Ve4vl5O2",
        "colab_type": "text"
      },
      "source": [
        "# Demo\n",
        "\n",
        "Since we don't have control over the launch time environment variables in the Google Colab VM after a notebook has started, if we try to write `import caffe` directly, it won't be found as it was installed in a non-default location `/usr/local`.\n",
        "\n",
        "(I haven't found a solution yet to relaunch the Notebook Server with new Environment variables)\n",
        "\n",
        "Hence, we can\n",
        "- set the environment variables\n",
        "- execute a script to save the outputs\n",
        "- view it later.\n",
        "\n",
        "Here, I am writing it to the folder I created earlier `drive-sync` on Google drive, so that I can access the outputs even after the Colab VM is terminated."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Uy9glnNDPes",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cd ctpn && \\\n",
        "  GLOG_minloglevel=2 \\\n",
        "    GLOG_logtostderr=1 \\\n",
        "    LD_LIBRARY_PATH=/usr/local/lib:$LD_LIBRARY_PATH \\\n",
        "    PYTHONPATH=/usr/local/python:$PYTHONPATH \\\n",
        "    python tools/demo_save.py --output_dir \"/content/gdrive/My Drive/drive-sync\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DRjHzbAss1TB",
        "colab_type": "text"
      },
      "source": [
        "We can view the output images in the following ways:\n",
        "\n",
        "- Navigating to our Google Drive folder\n",
        "- If we have enabled drive sync, we can view these files directly on our computer\n",
        "- Or through the following snippet\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vFTXhsGgD4hi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline\n",
        "import cv2\n",
        "from matplotlib import pyplot as plt\n",
        "FOLDER=\"/content/gdrive/My Drive/drive-sync\"\n",
        "for i in range(1, 4):\n",
        "  img = cv2.imread(f'{FOLDER}/output_img_{i}.jpg')\n",
        "  plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
        "  plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P008wVQ51o_H",
        "colab_type": "text"
      },
      "source": [
        "# Future Work\n",
        "\n",
        "- Now that CTPN works with NVCaffe, we can\n",
        "  - Reduce memory footprint with FP16 computation\n",
        "  - Measure and reduce time taken by the GPU part by wrapping the TensorRT compatible layers with the NVCaffe TRT Layer.\n",
        "\n",
        "\n",
        "- Since most of the layers in the CTPN project is compatible with `TensorRT`, we can create a `TRT plan` file which we can serve with [Triton Inference Server](https://github.com/NVIDIA/triton-inference-server)\n",
        "\n",
        "- For the CPU part, we can look at `multiprocessing` and `asyncio` to parallely handle the I/O bound pre-processing and CPU bound post processing.\n",
        "\n",
        "- Expose the Text detection capabilities over an API."
      ]
    }
  ]
}